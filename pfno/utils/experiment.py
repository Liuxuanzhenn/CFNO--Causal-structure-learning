"""
å®éªŒç®¡ç†å·¥å…·æ¨¡å—
æä¾›å®éªŒä¿å­˜ã€åŠ è½½ã€æŠ¥å‘Šç”Ÿæˆç­‰åŠŸèƒ½
"""

import json
import pickle
import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
import numpy as np
import pandas as pd


def save_experiment(results: Dict[str, Any], 
                   config: Dict[str, Any], 
                   save_dir: str,
                   experiment_name: str = "pfno_experiment") -> str:
    """
    ä¿å­˜å®éªŒç»“æœå’Œé…ç½®
    
    Args:
        results: å®éªŒç»“æœå­—å…¸
        config: é…ç½®å­—å…¸
        save_dir: ä¿å­˜ç›®å½•
        experiment_name: å®éªŒåç§°
        
    Returns:
        ä¿å­˜è·¯å¾„
    """
    save_path = Path(save_dir)
    save_path.mkdir(parents=True, exist_ok=True)
    
    # æ·»åŠ æ—¶é—´æˆ³
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_name = f"{experiment_name}_{timestamp}"
    
    # ä¿å­˜é…ç½®
    config_path = save_path / f"{experiment_name}_config.json"
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜ç»“æœï¼ˆå¤„ç†numpyæ•°ç»„ï¼‰
    def serialize_results(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, datetime.datetime):
            return obj.isoformat()
        raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
    
    results_json_path = save_path / f"{experiment_name}_results.json"
    with open(results_json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=serialize_results)
    
    # ä¿å­˜pickleç‰ˆæœ¬ï¼ˆä¿ç•™åŸå§‹æ•°æ®ç±»å‹ï¼‰
    results_pkl_path = save_path / f"{experiment_name}_results.pkl"
    with open(results_pkl_path, 'wb') as f:
        pickle.dump(results, f)
    
    # ç”ŸæˆæŠ¥å‘Š
    report_path = save_path / f"{experiment_name}_report.txt"
    generate_report(results, config, str(report_path))
    
    print(f"âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    return str(save_path)


def load_experiment(experiment_path: str) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    """
    åŠ è½½å®éªŒç»“æœå’Œé…ç½®
    
    Args:
        experiment_path: å®éªŒè·¯å¾„
        
    Returns:
        (results, config) å…ƒç»„
    """
    experiment_path = Path(experiment_path)
    
    if experiment_path.is_file():
        # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œä»æ–‡ä»¶åæ¨æ–­å®éªŒå
        experiment_dir = experiment_path.parent
        experiment_name = experiment_path.stem
        if experiment_name.endswith('_config'):
            experiment_name = experiment_name[:-7]
        elif experiment_name.endswith('_results'):
            experiment_name = experiment_name[:-8]
    else:
        # å¦‚æœæ˜¯ç›®å½•è·¯å¾„ï¼ŒæŸ¥æ‰¾æœ€æ–°çš„å®éªŒ
        experiment_dir = experiment_path
        experiment_files = list(experiment_dir.glob("*_config.json"))
        if not experiment_files:
            raise FileNotFoundError(f"åœ¨ {experiment_dir} ä¸­æ‰¾ä¸åˆ°å®éªŒé…ç½®æ–‡ä»¶")
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
        latest_config = max(experiment_files, key=lambda p: p.stat().st_mtime)
        experiment_name = latest_config.stem[:-7]
    
    # åŠ è½½é…ç½®
    config_path = experiment_dir / f"{experiment_name}_config.json"
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # åŠ è½½ç»“æœ
    results_path = experiment_dir / f"{experiment_name}_results.pkl"
    with open(results_path, 'rb') as f:
        results = pickle.load(f)
    
    return results, config


def generate_report(results: Dict[str, Any], 
                   config: Dict[str, Any], 
                   report_path: str):
    """
    ç”Ÿæˆå®éªŒæŠ¥å‘Š
    
    Args:
        results: å®éªŒç»“æœ
        config: é…ç½®ä¿¡æ¯
        report_path: æŠ¥å‘Šä¿å­˜è·¯å¾„
    """
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("                    PFNO å®éªŒæŠ¥å‘Š\n")
        f.write("="*80 + "\n\n")
        
        # å®éªŒåŸºæœ¬ä¿¡æ¯
        f.write("ğŸ“‹ å®éªŒä¿¡æ¯:\n")
        f.write("-"*40 + "\n")
        f.write(f"   ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # é…ç½®ä¿¡æ¯
        f.write("\nğŸ“ é…ç½®å‚æ•°:\n")
        f.write("-"*40 + "\n")
        
        for section, settings in config.items():
            f.write(f"   {section.upper()}:\n")
            if isinstance(settings, dict):
                for key, value in settings.items():
                    f.write(f"     {key}: {value}\n")
            else:
                f.write(f"     {settings}\n")
        
        # è¯„ä¼°ç»“æœ
        if 'evaluation' in results:
            eval_results = results['evaluation']
            f.write("\nğŸ¯ è¯„ä¼°ç»“æœ:\n")
            f.write("-"*40 + "\n")
            
            for metric, value in eval_results.items():
                if isinstance(value, (int, float)):
                    f.write(f"   {metric}: {value:.4f}\n")
                else:
                    f.write(f"   {metric}: {value}\n")
        
        f.write("\n")
        f.write("="*80 + "\n")


def compare_experiments(experiment_paths: List[str]) -> Dict[str, Any]:
    """
    æ¯”è¾ƒå¤šä¸ªå®éªŒçš„ç»“æœ
    
    Args:
        experiment_paths: å®éªŒè·¯å¾„åˆ—è¡¨
        
    Returns:
        æ¯”è¾ƒç»“æœå­—å…¸
    """
    comparison_data = []
    
    for exp_path in experiment_paths:
        try:
            results, config = load_experiment(exp_path)
            
            # æå–å®éªŒåç§°
            exp_name = Path(exp_path).name if Path(exp_path).is_dir() else Path(exp_path).stem
            
            # æå–æŒ‡æ ‡
            row_data = {'experiment': exp_name}
            
            # ä»è¯„ä¼°ç»“æœä¸­æå–æŒ‡æ ‡
            if 'evaluation' in results:
                eval_results = results['evaluation']
                for metric in ['f1', 'precision', 'recall', 'accuracy']:
                    if metric in eval_results:
                        row_data[metric] = eval_results[metric]
            
            comparison_data.append(row_data)
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å®éªŒ {exp_path} æ—¶å‡ºé”™: {e}")
            continue
    
    return {'experiments': comparison_data}


def create_experiment_summary(experiment_dir: str) -> Dict[str, Any]:
    """
    åˆ›å»ºå®éªŒç›®å½•çš„æ‘˜è¦
    
    Args:
        experiment_dir: å®éªŒç›®å½•è·¯å¾„
        
    Returns:
        å®éªŒæ‘˜è¦å­—å…¸
    """
    experiment_dir = Path(experiment_dir)
    
    if not experiment_dir.exists():
        raise FileNotFoundError(f"å®éªŒç›®å½•ä¸å­˜åœ¨: {experiment_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰å®éªŒæ–‡ä»¶
    config_files = list(experiment_dir.glob("*_config.json"))
    
    summary = {
        'directory': str(experiment_dir),
        'total_experiments': len(config_files),
        'experiment_list': [],
        'created_time': datetime.datetime.now().isoformat()
    }
    
    # åˆ†ææ¯ä¸ªå®éªŒ
    for config_file in config_files:
        experiment_name = config_file.stem[:-7]  # ç§»é™¤_configåç¼€
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            exp_info = {
                'name': experiment_name,
                'config_file': str(config_file),
                'created_time': datetime.datetime.fromtimestamp(
                    config_file.stat().st_ctime
                ).isoformat()
            }
            
            summary['experiment_list'].append(exp_info)
            
        except Exception as e:
            print(f"âš ï¸ åˆ†æå®éªŒ {experiment_name} æ—¶å‡ºé”™: {e}")
            continue
    
    return summary


def cleanup_old_experiments(experiment_dir: str, 
                           keep_last: int = 10,
                           dry_run: bool = True) -> List[str]:
    """
    æ¸…ç†æ—§çš„å®éªŒæ–‡ä»¶
    
    Args:
        experiment_dir: å®éªŒç›®å½•
        keep_last: ä¿ç•™æœ€è¿‘çš„å®éªŒæ•°é‡
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œï¼ˆä¸å®é™…åˆ é™¤ï¼‰
        
    Returns:
        è¢«åˆ é™¤ï¼ˆæˆ–å°†è¢«åˆ é™¤ï¼‰çš„æ–‡ä»¶åˆ—è¡¨
    """
    experiment_dir = Path(experiment_dir)
    
    if not experiment_dir.exists():
        return []
    
    # è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶å¹¶æŒ‰æ—¶é—´æ’åº
    config_files = list(experiment_dir.glob("*_config.json"))
    config_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    
    # ç¡®å®šè¦åˆ é™¤çš„æ–‡ä»¶
    to_delete = []
    
    if len(config_files) > keep_last:
        old_configs = config_files[keep_last:]
        
        for config_file in old_configs:
            experiment_name = config_file.stem[:-7]  # ç§»é™¤_configåç¼€
            
            # æ‰¾åˆ°ç›¸å…³çš„æ‰€æœ‰æ–‡ä»¶
            related_files = list(experiment_dir.glob(f"{experiment_name}_*"))
            to_delete.extend(related_files)
    
    # æ‰§è¡Œåˆ é™¤æ“ä½œ
    deleted_files = []
    
    for file_path in to_delete:
        if not dry_run:
            try:
                file_path.unlink()
                deleted_files.append(str(file_path))
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        else:
            deleted_files.append(str(file_path))
    
    if dry_run:
        print(f"ğŸ§ª è¯•è¿è¡Œæ¨¡å¼ï¼šå°†åˆ é™¤ {len(deleted_files)} ä¸ªæ–‡ä»¶")
    else:
        print(f"ğŸ—‘ï¸ å·²åˆ é™¤ {len(deleted_files)} ä¸ªæ—§å®éªŒæ–‡ä»¶")
    
    return deleted_files


__all__ = [
    'save_experiment',
    'load_experiment',
    'generate_report',
    'compare_experiments',
    'create_experiment_summary',
    'cleanup_old_experiments'
] 