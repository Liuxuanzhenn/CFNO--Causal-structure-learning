"""
PFNOé…ç½®åŠ è½½å™¨
ä½¿ç”¨utils/config.pyç®¡ç†YAMLé…ç½®æ–‡ä»¶
"""

import os
import yaml
import warnings
from pathlib import Path
from typing import Dict, Any, Optional

# ä½¿ç”¨ç›¸å¯¹å¯¼å…¥æ›¿ä»£sys.path.append
from .utils.config import load_config, save_config, validate_config, merge_configs


# é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
DEFAULT_CONFIG_PATH = Path(__file__).parent / "pfno_config.yaml"


def get_pfno_config(config_path: Optional[str] = None) -> Dict[str, Any]:
    """
    è·å–PFNOé…ç½®
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨pfno_config.yaml
        
    Returns:
        é…ç½®å­—å…¸
    """
    if config_path is None:
        config_path = DEFAULT_CONFIG_PATH
    
    # åŠ è½½é…ç½®
    config = load_config(config_path)
    
    # ğŸ”§ é…ç½®é”®æ˜ å°„ - å¤„ç†æ—§æ ¼å¼åˆ°æ–°æ ¼å¼çš„è½¬æ¢
    config = _map_config_keys(config)
    
    # éªŒè¯é…ç½®
    if not validate_config(config, config_type="pfno"):
        raise ValueError("é…ç½®éªŒè¯å¤±è´¥")
    
    return config


def _map_config_keys(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ˜ å°„é…ç½®é”®ï¼Œæ”¯æŒä¸åŒçš„é…ç½®æ ¼å¼
    
    Args:
        config: åŸå§‹é…ç½®
        
    Returns:
        æ˜ å°„åçš„é…ç½®
    """
    mapped_config = config.copy()
    
    # å¦‚æœæœ‰ 'model' é”®ä½†æ²¡æœ‰ 'architecture' é”®ï¼Œè¿›è¡Œæ˜ å°„
    if 'model' in config and 'architecture' not in config:
        mapped_config['architecture'] = config['model'].copy()
        # ç§»é™¤modelé”®ä»¥é¿å…å†²çª
        del mapped_config['model']
        print("ğŸ”§ é…ç½®æ˜ å°„: 'model' -> 'architecture'")
    
    # ç¡®ä¿æ¦‚ç‡é…ç½®å­˜åœ¨
    if 'probabilistic' not in mapped_config:
        # å¦‚æœarchitectureä¸­æœ‰æ¦‚ç‡å‚æ•°ï¼Œæå–å‡ºæ¥
        if 'architecture' in mapped_config:
            arch = mapped_config['architecture']
            prob_keys = ['n_samples', 'monte_carlo_samples', 'confidence_threshold', 'uncertainty_threshold']
            prob_config = {}
            
            for key in prob_keys:
                if key in arch:
                    prob_config[key] = arch[key]
                    del arch[key]
            
            if prob_config:
                mapped_config['probabilistic'] = prob_config
                print("ğŸ”§ é…ç½®æ˜ å°„: æ¦‚ç‡å‚æ•°ä» 'architecture' æå–åˆ° 'probabilistic'")
    
    return mapped_config


def update_config_from_args(config: Dict[str, Any], args) -> Dict[str, Any]:
    """
    ä»å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
    
    Args:
        config: åŸºç¡€é…ç½®
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
        
    Returns:
        æ›´æ–°åçš„é…ç½®
    """
    updates = {}
    
    # è®­ç»ƒå‚æ•°
    if hasattr(args, 'epochs') and args.epochs:
        updates['training'] = {'num_epochs': args.epochs}
    
    if hasattr(args, 'lr') and args.lr:
        if 'training' not in updates:
            updates['training'] = {}
        updates['training']['learning_rate'] = args.lr
    
    if hasattr(args, 'batch_size') and args.batch_size:
        if 'training' not in updates:
            updates['training'] = {}
        updates['training']['batch_size'] = args.batch_size
    
    # æ•°æ®å‚æ•°
    if hasattr(args, 'data_file') and args.data_file:
        updates['data'] = {'file_path': args.data_file}
    
    if hasattr(args, 'ground_truth_file') and args.ground_truth_file:
        if 'data' not in updates:
            updates['data'] = {}
        updates['data']['ground_truth_file'] = args.ground_truth_file
    
    # é¢„å¤„ç†æ–¹æ³•
    if hasattr(args, 'preprocessing_method') and args.preprocessing_method:
        if 'data' not in updates:
            updates['data'] = {}
        updates['data']['preprocessing'] = {'method': args.preprocessing_method}
    
    # æ¦‚ç‡å‚æ•°
    if hasattr(args, 'n_samples') and args.n_samples:
        updates['probabilistic'] = {'n_samples': args.n_samples}
    
    if hasattr(args, 'confidence_threshold') and args.confidence_threshold:
        if 'probabilistic' not in updates:
            updates['probabilistic'] = {}
        updates['probabilistic']['confidence_threshold'] = args.confidence_threshold
    
    # è°ƒè¯•å‚æ•°
    if hasattr(args, 'debug') and args.debug:
        updates['debug_visualization'] = {'debug_mode': True, 'verbose_logging': True}
    
    # åˆå¹¶é…ç½®
    if updates:
        config = merge_configs(config, updates)
    
    return config


def print_config_summary(config: Optional[Dict[str, Any]] = None):
    """
    æ‰“å°é…ç½®æ‘˜è¦
    
    Args:
        config: é…ç½®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™åŠ è½½é»˜è®¤é…ç½®
    """
    if config is None:
        config = get_pfno_config()
    
    print("\n" + "="*60)
    print("                PFNOé…ç½®æ‘˜è¦")
    print("="*60)
    
    # æ¶æ„å‚æ•°
    arch = config.get('architecture', {})
    print(f"ğŸ—ï¸  æ¶æ„å‚æ•°:")
    print(f"   â€¢ å‚…é‡Œå¶æ¨¡å¼æ•°: {arch.get('n_modes', 'N/A')}")
    print(f"   â€¢ éšè—é€šé“æ•°: {arch.get('hidden_channels', 'N/A')}")
    print(f"   â€¢ FNOå±‚æ•°: {arch.get('n_layers', 'N/A')}")
    print(f"   â€¢ Dropoutç‡: {arch.get('dropout', 'N/A')}")
    
    # æ¦‚ç‡å‚æ•°
    prob = config.get('probabilistic', {})
    print(f"\nğŸ² æ¦‚ç‡å‚æ•°:")
    print(f"   â€¢ é‡‡æ ·æ•°é‡: {prob.get('n_samples', 'N/A')}")
    print(f"   â€¢ ç½®ä¿¡åº¦é˜ˆå€¼: {prob.get('confidence_threshold', 'N/A')}")
    print(f"   â€¢ è’™ç‰¹å¡æ´›é‡‡æ ·: {prob.get('monte_carlo_samples', 'N/A')}")
    
    # è®­ç»ƒå‚æ•°
    training = config.get('training', {})
    loss_weights = training.get('loss_weights', {})
    print(f"\nğŸš€ è®­ç»ƒå‚æ•°:")
    print(f"   â€¢ è®­ç»ƒè½®æ•°: {training.get('num_epochs', 'N/A')}")
    print(f"   â€¢ å­¦ä¹ ç‡: {training.get('learning_rate', 'N/A')}")
    print(f"   â€¢ æ‰¹é‡å¤§å°: {training.get('batch_size', 'N/A')}")
    print(f"   â€¢ ä¼˜åŒ–å™¨: {training.get('optimizer', 'N/A')}")
    print(f"   â€¢ L1æ­£åˆ™åŒ–æƒé‡: {loss_weights.get('l1_regularization', 'N/A')}")
    print(f"   â€¢ L2æ­£åˆ™åŒ–æƒé‡: {loss_weights.get('l2_regularization', 'N/A')}")
    print(f"   â€¢ DAGçº¦æŸæƒé‡: {loss_weights.get('dag_constraint', 'N/A')}")
    
    # æ•°æ®å‚æ•°
    data = config.get('data', {})
    print(f"\nğŸ“Š æ•°æ®å‚æ•°:")
    print(f"   â€¢ æ•°æ®æ–‡ä»¶: {data.get('file_path', 'N/A')}")
    print(f"   â€¢ åºåˆ—é•¿åº¦: {data.get('sequence_length', 'N/A')}")
    print(f"   â€¢ è®­ç»ƒæ¯”ä¾‹: {data.get('train_ratio', 'N/A')}")
    preprocessing = data.get('preprocessing', {})
    print(f"   â€¢ é¢„å¤„ç†æ–¹æ³•: {preprocessing.get('method', 'N/A')}")
    
    print("="*60)


def save_config_to_file(config: Dict[str, Any], filepath: str):
    """
    ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
    
    Args:
        config: é…ç½®å­—å…¸
        filepath: ä¿å­˜è·¯å¾„
    """
    save_config(config, filepath)
    print(f"é…ç½®å·²ä¿å­˜åˆ°: {filepath}")


def load_config_from_file(filepath: str) -> Dict[str, Any]:
    """
    ä»æ–‡ä»¶åŠ è½½é…ç½®
    
    Args:
        filepath: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        é…ç½®å­—å…¸
    """
    return load_config(filepath)


# å‘åå…¼å®¹çš„é…ç½®å¸¸é‡
def get_legacy_config():
    """è·å–ä¸åŸpfno_config.pyå…¼å®¹çš„é…ç½®æ ¼å¼"""
    config = get_pfno_config()
    
    # è½¬æ¢ä¸ºåŸæ¥çš„æ ¼å¼
    legacy_config = {
        'PFNO_ARCHITECTURE': config.get('architecture', {}),
        'PROBABILISTIC_PARAMS': config.get('probabilistic', {}),
        'CAUSAL_DISCOVERY': config.get('causal', {}),
        'TRAINING_STRATEGY': config.get('training', {}),
        'PFNO_DATA_PARAMS': config.get('data', {}),
        'EVALUATION_PARAMS': config.get('evaluation', {}),
        'PROBABILITY_SCALING': config.get('probability_scaling', {}),
        'RANDOM_SEED': config.get('random_seed', {}),
        'DEBUG_VISUALIZATION': config.get('debug_visualization', {})
    }
    
    return legacy_config


class JointLearningConfigLoader:
    """
    ç»Ÿä¸€çš„é…ç½®åŠ è½½å™¨ï¼Œæ”¯æŒä»YAMLæ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°åŠ è½½é…ç½®ã€‚
    """
    def __init__(self, config_path: str = None):
        self.config_path = config_path
        self.config = self._load_config()

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½ä¸»é…ç½®æ–‡ä»¶"""
        if self.config_path is None:
            # å¦‚æœæœªæä¾›è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
            return self._get_default_config()
        
        try:
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            warnings.warn(f"é…ç½®æ–‡ä»¶ {self.config_path} æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
            return self._get_default_config()

    def _get_default_config(self) -> Dict[str, Any]:
        """æä¾›ä¸€ä¸ªç¡¬ç¼–ç çš„é»˜è®¤é…ç½®"""
        return get_pfno_config()

    def update_from_args(self, args):
        """ç”¨å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®"""
        self.config = update_config_from_args(self.config, args)

    def get_joint_learning_config(self) -> Dict[str, Any]:
        """è·å–è”åˆå­¦ä¹ ç‰¹å®šçš„é…ç½®"""
        return self.config.get('joint_learning', {})

    def get_loss_weights(self) -> Dict[str, float]:
        """è·å–æŸå¤±æƒé‡"""
        return self.config.get('training', {}).get('loss_weights', {})

    def get_model_config(self, num_nodes: int, sequence_length: int) -> Dict[str, Any]:
        """ä»ä¸»é…ç½®ä¸­æå–å¹¶æ„å»ºæ¨¡å‹ç‰¹å®šçš„é…ç½®å­—å…¸"""
        arch_config = self.config.get('architecture', {})
        prob_config = self.config.get('probabilistic', {})
        causal_config = self.config.get('causal', {})
        joint_config = self.get_joint_learning_config()
        joint_enabled = joint_config.get('enabled', False)
        
        model_config = {
            # åŸºç¡€å‚æ•°
            'n_modes': arch_config.get('n_modes', [8, 8]),
            'hidden_channels': arch_config.get('hidden_channels', 64),
            'lifting_channels': arch_config.get('lifting_channels', 256),
            'projection_channels': arch_config.get('projection_channels', 256),
            'n_layers': arch_config.get('n_layers', 2),
            'dropout': arch_config.get('dropout', 0.1),
            
            # èŠ‚ç‚¹å’Œåºåˆ—ä¿¡æ¯
            'num_nodes': num_nodes,
            'sequence_length': sequence_length,
            
            # æ¦‚ç‡å‚æ•°
            'n_samples': prob_config.get('n_samples', 10),
            'numerical_stability_check': prob_config.get('numerical_stability_check', True),
            
            # å› æœå‚æ•°
            'use_dag_constraint': causal_config.get('use_dag_constraint', True),
            'causal_reg_weight': causal_config.get('causal_reg_weight', 0.001),
            'gradient_clipping': causal_config.get('gradient_clipping', 1.0),
            
            # âœ¨ è”åˆå­¦ä¹ é…ç½®
            'joint_learning_config': joint_config if joint_enabled else None
        }
        
        return model_config
    
    def create_model(self, num_nodes: int, sequence_length: int):
        """
        åˆ›å»ºé…ç½®å¥½çš„æ¨¡å‹å®ä¾‹
        
        Args:
            num_nodes: èŠ‚ç‚¹æ•°é‡
            sequence_length: åºåˆ—é•¿åº¦
            
        Returns:
            é…ç½®å¥½çš„EnhancedProbabilisticCausalPFNOå®ä¾‹
        """
        from .probabilistic_causal_pfno import EnhancedProbabilisticCausalPFNO
        
        model_config = self.get_model_config(num_nodes, sequence_length)
        model = EnhancedProbabilisticCausalPFNO(**model_config)
        
        return model

    def print_config_summary(self):
        """æ‰“å°æœ€ç»ˆçš„é…ç½®æ‘˜è¦"""
        print_config_summary(self.config)

def load_joint_learning_config(config_path: str = None) -> JointLearningConfigLoader:
    """
    åŠ è½½å¹¶è¿”å›è”åˆå­¦ä¹ é…ç½®åŠ è½½å™¨å®ä¾‹
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        JointLearningConfigLoaderå®ä¾‹
    """
    return JointLearningConfigLoader(config_path)


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®åŠ è½½
    config = get_pfno_config()
    print_config_summary(config)

    # åŠ è½½é…ç½®
    config_loader = load_joint_learning_config()
    
    # æ‰“å°é…ç½®æ‘˜è¦
    config_loader.print_config_summary()
    
    # åˆ›å»ºæ¨¡å‹
    model = config_loader.create_model(num_nodes=5, sequence_length=20)
    print(f"\nğŸš€ æˆåŠŸåˆ›å»ºæ¨¡å‹ï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}") 