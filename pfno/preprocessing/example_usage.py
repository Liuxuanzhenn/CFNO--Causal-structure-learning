#!/usr/bin/env python3
"""
PFNOå¢å¼ºé¢„å¤„ç†ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å››ç§ä¸åŒçš„é¢„å¤„ç†æ–¹æ³•ï¼š
1. minimal - æœ€å°é¢„å¤„ç†
2. standard - æ ‡å‡†é¢„å¤„ç†ï¼ˆæ¨èï¼‰
3. comprehensive - å…¨é¢é¢„å¤„ç†
4. time_series_focused - æ—¶é—´åºåˆ—ä¸“ç”¨
"""

import sys
import os
# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from pfno.pfno_config import get_pfno_config, PFNO_CONFIG
import argparse


def demonstrate_preprocessing_methods():
    """æ¼”ç¤ºä¸åŒçš„é¢„å¤„ç†æ–¹æ³•"""
    
    print("ğŸ¯ PFNOå¢å¼ºé¢„å¤„ç†ç³»ç»Ÿæ¼”ç¤º")
    print("="*60)
    
    # è·å–åŸºç¡€é…ç½®
    base_config = PFNO_CONFIG.copy()
    
    # é¢„å¤„ç†æ–¹æ³•è¯´æ˜
    preprocessing_methods = {
        'minimal': {
            'name': 'æœ€å°é¢„å¤„ç†',
            'description': 'ä»…å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼Œä¸è¿›è¡Œæ ‡å‡†åŒ–',
            'use_case': 'é€‚ç”¨äºæ•°æ®è´¨é‡è¾ƒå¥½ï¼Œå¸Œæœ›ä¿æŒåŸå§‹æ•°æ®åˆ†å¸ƒçš„åœºæ™¯'
        },
        'standard': {
            'name': 'æ ‡å‡†é¢„å¤„ç†ï¼ˆæ¨èï¼‰',
            'description': 'åŒ…å«åŸºæœ¬æ¸…ç† + Z-scoreæ ‡å‡†åŒ–',
            'use_case': 'é€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯ï¼Œå¹³è¡¡äº†æ•°æ®è´¨é‡å’Œå¤„ç†æ•ˆæœ'
        },
        'comprehensive': {
            'name': 'å…¨é¢é¢„å¤„ç†',
            'description': 'åŒ…å«æ‰€æœ‰é¢„å¤„ç†æ­¥éª¤ï¼ŒåŒ…æ‹¬å¼‚å¸¸å€¼å¤„ç†å’Œå¹³ç¨³æ€§æ£€æŸ¥',
            'use_case': 'é€‚ç”¨äºå™ªå£°è¾ƒå¤šã€éœ€è¦æ·±åº¦æ¸…ç†çš„æ•°æ®'
        },
        'time_series_focused': {
            'name': 'æ—¶é—´åºåˆ—ä¸“ç”¨',
            'description': 'ä¸“ä¸ºæ—¶é—´åºåˆ—æ•°æ®è®¾è®¡ï¼ŒåŒ…å«æ’å€¼ã€å»è¶‹åŠ¿ç­‰',
            'use_case': 'é€‚ç”¨äºå…·æœ‰æ˜æ˜¾æ—¶åºç‰¹å¾çš„æ•°æ®'
        }
    }
    
    for method, info in preprocessing_methods.items():
        print(f"\nğŸ“‹ {info['name']} ({method})")
        print(f"   æè¿°: {info['description']}")
        print(f"   é€‚ç”¨åœºæ™¯: {info['use_case']}")
        
        # æ˜¾ç¤ºè¯¥æ–¹æ³•çš„è¯¦ç»†é…ç½®
        method_config = base_config['data']['preprocessing'][method]
        print(f"   ä¸»è¦å‚æ•°:")
        
        if method_config.get('handle_missing'):
            print(f"     â€¢ ç¼ºå¤±å€¼å¤„ç†: {method_config.get('missing_method', 'interpolate')}")
        
        if method_config.get('handle_outliers'):
            print(f"     â€¢ å¼‚å¸¸å€¼å¤„ç†: {method_config.get('outlier_method', 'iqr')} (é˜ˆå€¼: {method_config.get('outlier_threshold', 3.0)})")
        
        if method_config.get('normalize'):
            print(f"     â€¢ æ ‡å‡†åŒ–: {method_config.get('normalization_method', 'zscore')}")
        else:
            print(f"     â€¢ æ ‡å‡†åŒ–: æ— ")
            
        # ç‰¹æ®Šå¤„ç†æ­¥éª¤
        special_steps = []
        if method == 'comprehensive':
            if method_config.get('check_stationarity'):
                special_steps.append("å¹³ç¨³æ€§æ£€æŸ¥")
            if method_config.get('remove_trend'):
                special_steps.append("å»è¶‹åŠ¿")
            if method_config.get('smooth_data'):
                special_steps.append("æ•°æ®å¹³æ»‘")
                
        elif method == 'time_series_focused':
            if method_config.get('detrend'):
                special_steps.append("å»è¶‹åŠ¿")
            if method_config.get('apply_filter'):
                special_steps.append(f"æ»¤æ³¢ ({method_config.get('filter_type', 'butterworth')})")
            if method_config.get('missing_method') == 'spline':
                special_steps.append("æ ·æ¡æ’å€¼")
        
        if special_steps:
            print(f"     â€¢ ç‰¹æ®Šæ­¥éª¤: {', '.join(special_steps)}")


def run_preprocessing_example(method='standard', data_file=None):
    """è¿è¡Œé¢„å¤„ç†ç¤ºä¾‹"""
    
    print(f"\nğŸš€ è¿è¡Œ '{method}' é¢„å¤„ç†ç¤ºä¾‹")
    print("="*50)
    
    # è·å–é…ç½®å¹¶è®¾ç½®é¢„å¤„ç†æ–¹æ³•
    config = PFNO_CONFIG.copy()
    config['data']['preprocessing']['method'] = method
    
    # å¦‚æœæŒ‡å®šäº†æ•°æ®æ–‡ä»¶ï¼Œæ›´æ–°è·¯å¾„
    if data_file:
        config['data']['file_path'] = data_file
        print(f"ğŸ“‚ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {data_file}")
    else:
        print(f"ğŸ“‚ ä½¿ç”¨é»˜è®¤æ•°æ®æ–‡ä»¶: {config['data']['file_path']}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(config['data']['file_path']):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {config['data']['file_path']}")
        print("è¯·ç¡®ä¿dataç›®å½•ä¸‹æœ‰generated_time_series2.csvæ–‡ä»¶ï¼Œæˆ–ä½¿ç”¨--data_fileæŒ‡å®šå…¶ä»–æ–‡ä»¶")
        return
    
    try:
        # å¯¼å…¥å¹¶è¿è¡Œé¢„å¤„ç† - ä½¿ç”¨æ–°çš„è·¯å¾„
        from pfno.preprocessing.data_loader import load_pfno_data
        
        # è¿è¡Œæ•°æ®åŠ è½½å’Œé¢„å¤„ç†
        (train_dataloader, val_dataloader, seq_length, num_nodes, 
         preprocessor, raw_data, preprocessing_info) = load_pfno_data(config)
        
        print(f"\nâœ… é¢„å¤„ç†æˆåŠŸå®Œæˆ!")
        print(f"   â€¢ é¢„å¤„ç†æ–¹æ³•: {preprocessing_info['method']}")
        print(f"   â€¢ æ‰§è¡Œæ­¥éª¤æ•°: {len(preprocessing_info['steps'])}")
        print(f"   â€¢ æœ€ç»ˆæ•°æ®ç»´åº¦: èŠ‚ç‚¹æ•°={num_nodes}, åºåˆ—é•¿åº¦={seq_length}")
        print(f"   â€¢ è®­ç»ƒæ‰¹æ¬¡: {len(train_dataloader)}, éªŒè¯æ‰¹æ¬¡: {len(val_dataloader)}")
        
        # æ˜¾ç¤ºé¢„å¤„ç†æ­¥éª¤è¯¦æƒ…
        print(f"\nğŸ“‹ é¢„å¤„ç†æ­¥éª¤è¯¦æƒ…:")
        for i, step in enumerate(preprocessing_info['steps'], 1):
            print(f"   {i}. {step}")
            
        # ä¿å­˜é¢„å¤„ç†å™¨ä¿¡æ¯
        if hasattr(preprocessor, 'scalers') and preprocessor.scalers:
            print(f"\nğŸ’¾ æ ‡å‡†åŒ–å™¨ä¿¡æ¯:")
            print(f"   â€¢ å·²ä¸º {len(preprocessor.scalers)} ä¸ªèŠ‚ç‚¹åˆ›å»ºæ ‡å‡†åŒ–å™¨")
            
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…æ‰€éœ€ä¾èµ–åŒ…")
        return False
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='PFNOå¢å¼ºé¢„å¤„ç†ç³»ç»Ÿæ¼”ç¤º',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ˜¾ç¤ºæ‰€æœ‰é¢„å¤„ç†æ–¹æ³•è¯´æ˜
  python pfno/preprocessing/example_usage.py --demo
  
  # è¿è¡Œæ ‡å‡†é¢„å¤„ç†ç¤ºä¾‹
  python pfno/preprocessing/example_usage.py --method standard
  
  # è¿è¡Œæ—¶é—´åºåˆ—ä¸“ç”¨é¢„å¤„ç†
  python pfno/preprocessing/example_usage.py --method time_series_focused --data_file data/your_data.csv
  
  # è¿è¡Œå…¨é¢é¢„å¤„ç†
  python pfno/preprocessing/example_usage.py --method comprehensive
        """
    )
    
    parser.add_argument('--demo', action='store_true',
                       help='æ˜¾ç¤ºæ‰€æœ‰é¢„å¤„ç†æ–¹æ³•çš„è¯´æ˜')
    parser.add_argument('--method', type=str, 
                       choices=['minimal', 'standard', 'comprehensive', 'time_series_focused'],
                       default='standard',
                       help='è¦æ¼”ç¤ºçš„é¢„å¤„ç†æ–¹æ³•')
    parser.add_argument('--data_file', type=str,
                       help='æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„ï¼‰')
    
    args = parser.parse_args()
    
    if args.demo:
        demonstrate_preprocessing_methods()
    else:
        success = run_preprocessing_example(args.method, args.data_file)
        if success:
            print(f"\nğŸ‰ '{args.method}' é¢„å¤„ç†æ¼”ç¤ºæˆåŠŸå®Œæˆ!")
        else:
            print(f"\nğŸ’¥ '{args.method}' é¢„å¤„ç†æ¼”ç¤ºå¤±è´¥!")
            sys.exit(1)


if __name__ == '__main__':
    main() 